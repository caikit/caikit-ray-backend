# Caikit Template

Template with an example repo for spinning up a runtime on [caikit](https://github.com/caikit/caikit)

### Configure environment
You must first set the location to any config files. For example, we are exporting the `demo_config` file below:

```shell
export CONFIG_FILES=demo_config.yml
```
This configures the server to work for this demo.


### Starting the runtime (enables training and inference server)

```shell
python3 demo/development/start_runtime.py
```

- `start_runtime.py` will automatically load the models available in `demo/user/models` folder. This path is configurable in the `demo_config.yml` file via the `runtime.local_models_dir` field.

### Call Caikit Runtime for Inference

In a separate terminal, export the demo config file using `export CONFIG_FILES=demo_config.yml`, and execute the following command to make a call to the runtime server for inferencing.

```shell
python3 demo/user/infer_via_server.py
```

- The above script will use `dummy_model` available in `demo/user/models` folder to make the inference call.

### Call Caikit Runtime for Training

In a separate terminal, export the demo config file using `export CONFIG_FILES=demo_config.yml`, and execute the following command to train a model for the `SampleBlock` module available in `caikit_example/example/sample_block.py`

```shell
python3 demo/user/train_via_server.py
```

- The above script will kick off a training in runtime (started above) using sample training data available [here](demo/user/demo_data/sample_data.csv).
- Once the model is trained (which in this example would be instantly), the model will get saved in the `demo/user/models` folder. This output path is also configurable in the `demo_config.yml` file via the `runtime.training.output_dir` field.
- Once the model is trained, it is stored in the format of `<training.output_dir>/<uuid-for-training>/<custom-model-name>`. where:
    - `<training.output_dir>` is the output directory path configured above.
    - `uuid-for-training` is the unique UUID generated by `caikit.runtime` to uniquely identify the training request. This gets returned in the response of a training request.
    - `<custom-model-name>` is a custom model name configured when sending the training request.
- To use the trained model for inferencing, either copy the `<custom-model-name>` in `local_models_dir` folder, or change the folder path in `demo_config.yml` for `local_models_dir` field.
- Please note that the server needs to be restarted for the new models to automatically get loaded.
- `caikit.runtime` also supports dynamically load the models. However, this tutorial currently doesn't showcase that. Please check documentation for further details on that.
